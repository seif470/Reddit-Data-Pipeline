[2024-08-03T13:44:52.597+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-08-03T13:44:50.634037+00:00 [queued]>
[2024-08-03T13:44:52.612+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-08-03T13:44:50.634037+00:00 [queued]>
[2024-08-03T13:44:52.613+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-08-03T13:44:52.636+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-08-03 13:44:50.634037+00:00
[2024-08-03T13:44:52.643+0000] {standard_task_runner.py:57} INFO - Started process 53 to run task
[2024-08-03T13:44:52.649+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'manual__2024-08-03T13:44:50.634037+00:00', '--job-id', '636', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmp3mafoz8m']
[2024-08-03T13:44:52.650+0000] {standard_task_runner.py:85} INFO - Job 636: Subtask reddit_extraction
[2024-08-03T13:44:52.722+0000] {task_command.py:416} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-08-03T13:44:50.634037+00:00 [running]> on host 8eab068d030e
[2024-08-03T13:44:52.862+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Seif Yasser' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-08-03T13:44:50.634037+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-08-03T13:44:50.634037+00:00'
[2024-08-03T13:44:52.868+0000] {logging_mixin.py:151} INFO - connected to reddit!
[2024-08-03T13:44:54.310+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "My dad in particular is interested in what my new role actually is but I struggle to articulate the process of what I’m doing other than ”I’m moving data from one place to another to help people make decisions”.\n\nIf I try to go any deeper than that I get way too technical and he struggles to grasp the concept.\n\nIf it helps at all with creating an analogy my dad has owned a dry cleaners, been a carpenter, and worked at an aerospace manufacturing facility.\n\nEDIT: I'd like to almost work through a simple example with him if possible, I'd like to go a level deeper than a basic analogy without getting too technical.\n\nEDIT 2: After mulling it over and reading the comments I came up with a process specific to his business (POS system) that I can use to explain it in a way I believe he will be able to understand.", 'author_fullname': 't2_fgc39', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How do I explain data engineering to my parents?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eia2pj', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.91, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 93, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 93, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1722632840.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722605332.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>My dad in particular is interested in what my new role actually is but I struggle to articulate the process of what I’m doing other than ”I’m moving data from one place to another to help people make decisions”.</p>\n\n<p>If I try to go any deeper than that I get way too technical and he struggles to grasp the concept.</p>\n\n<p>If it helps at all with creating an analogy my dad has owned a dry cleaners, been a carpenter, and worked at an aerospace manufacturing facility.</p>\n\n<p>EDIT: I&#39;d like to almost work through a simple example with him if possible, I&#39;d like to go a level deeper than a basic analogy without getting too technical.</p>\n\n<p>EDIT 2: After mulling it over and reading the comments I came up with a process specific to his business (POS system) that I can use to explain it in a way I believe he will be able to understand.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1eia2pj', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='TheOnlinePolak'), 'discussion_type': None, 'num_comments': 89, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eia2pj/how_do_i_explain_data_engineering_to_my_parents/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eia2pj/how_do_i_explain_data_engineering_to_my_parents/', 'subreddit_subscribers': 201664, 'created_utc': 1722605332.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.311+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "We are using a series of Spark SQL statements on normalized tables.\n\nOur raw data is about 1 billion rows per day with about 50 columns.  Columns are things like cust\\_id, country\\_id, product\\_id, etc. We then join this data to about 30 other tables to get cust\\_name, cust\\_country, product\\_name etc and end up with about 250 columns. Job runs every 15 mins and the 30 or so tables are joined in a sequence so no more than 1-3 tables per join. That makes each job about 15 steps.\n\nEvery column and join has very complicated logic like if cust\\_id IN(x,y,x) and country\\_id NOT IN(a,b,c) and product\\_id like '%Google%' then X else Y.\n\nI can't think of a tech solution to simplify this. My only thought is to simplify the requirements somehow so the logic itself is less complex.", 'author_fullname': 't2_szg2zfxvl', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How do you handle very complicated ETL jobs?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eicw3t', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.97, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 52, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 52, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1722615252.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722612315.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>We are using a series of Spark SQL statements on normalized tables.</p>\n\n<p>Our raw data is about 1 billion rows per day with about 50 columns.  Columns are things like cust_id, country_id, product_id, etc. We then join this data to about 30 other tables to get cust_name, cust_country, product_name etc and end up with about 250 columns. Job runs every 15 mins and the 30 or so tables are joined in a sequence so no more than 1-3 tables per join. That makes each job about 15 steps.</p>\n\n<p>Every column and join has very complicated logic like if cust_id IN(x,y,x) and country_id NOT IN(a,b,c) and product_id like &#39;%Google%&#39; then X else Y.</p>\n\n<p>I can&#39;t think of a tech solution to simplify this. My only thought is to simplify the requirements somehow so the logic itself is less complex.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1eicw3t', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Trick-Interaction396'), 'discussion_type': None, 'num_comments': 30, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eicw3t/how_do_you_handle_very_complicated_etl_jobs/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eicw3t/how_do_you_handle_very_complicated_etl_jobs/', 'subreddit_subscribers': 201664, 'created_utc': 1722612315.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.312+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'To step away a bit from imposter syndrome post, in a more optimistic approach - how good are you? When compared with the environment you are in?\n\nThought I was pretty good until I end up in a GCP project where I had to use Apache Beam (with Java) - scrum was nowhere to be found - project was cahotic and I learned that I wasn’t “strong” enough to impose  good practices from the beginning and to lead a team.\n\nNow I’m on a better project/company, much more suited for me - not only technical but also in terms of team, responsibilities, etc.\nGCP project was still a valuable experience, it made me value the importance of good practices, documentation, planning, etc.\n', 'author_fullname': 't2_837ynoa5', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How good are you?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eikxop', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 46, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 46, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722631940.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>To step away a bit from imposter syndrome post, in a more optimistic approach - how good are you? When compared with the environment you are in?</p>\n\n<p>Thought I was pretty good until I end up in a GCP project where I had to use Apache Beam (with Java) - scrum was nowhere to be found - project was cahotic and I learned that I wasn’t “strong” enough to impose  good practices from the beginning and to lead a team.</p>\n\n<p>Now I’m on a better project/company, much more suited for me - not only technical but also in terms of team, responsibilities, etc.\nGCP project was still a valuable experience, it made me value the importance of good practices, documentation, planning, etc.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1eikxop', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Apolo_reader'), 'discussion_type': None, 'num_comments': 30, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eikxop/how_good_are_you/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eikxop/how_good_are_you/', 'subreddit_subscribers': 201664, 'created_utc': 1722631940.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.313+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hey all, I'm a python developer looking to go deeper in the world of data engineering. Would love book recs on the following:\n\n* Clickhouse\n* Deep dives into important & specific topics\n* General fundamentals, but only if you really liked it (I find the general fundamentals books can sometimes drag on with basic topics). Though I would love a concise general fundamentals book\n* Anything I might have missed\n\nThank you!", 'author_fullname': 't2_vhu5zelh', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Favorite books?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eim8zm', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.99, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 41, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 41, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722635258.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey all, I&#39;m a python developer looking to go deeper in the world of data engineering. Would love book recs on the following:</p>\n\n<ul>\n<li>Clickhouse</li>\n<li>Deep dives into important &amp; specific topics</li>\n<li>General fundamentals, but only if you really liked it (I find the general fundamentals books can sometimes drag on with basic topics). Though I would love a concise general fundamentals book</li>\n<li>Anything I might have missed</li>\n</ul>\n\n<p>Thank you!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1eim8zm', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Consistent-Total-846'), 'discussion_type': None, 'num_comments': 13, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eim8zm/favorite_books/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eim8zm/favorite_books/', 'subreddit_subscribers': 201664, 'created_utc': 1722635258.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.314+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Do you work in retail,finance,tech,Healthcare,etc? Do you enjoy the industry you work in as a Data Engineer. ', 'author_fullname': 't2_3v3qhgn7', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What Industry Do You Work In As A Data Engineer ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eivu0m', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.94, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 46, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 46, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722663923.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Do you work in retail,finance,tech,Healthcare,etc? Do you enjoy the industry you work in as a Data Engineer. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1eivu0m', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='valorallure01'), 'discussion_type': None, 'num_comments': 97, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eivu0m/what_industry_do_you_work_in_as_a_data_engineer/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eivu0m/what_industry_do_you_work_in_as_a_data_engineer/', 'subreddit_subscribers': 201664, 'created_utc': 1722663923.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.317+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'They recently pushed new code to prod that seriously had me scratching my head.\n\nI get it, sometimes datatypes change, and fivetran will pick them up.  So they rename the existing column as deprecated, add the new one (with the new datatype), then drop the old one.  And fair enough that we had some structures that included those columns they tried to drop.  I get that\'s a risk and not ideal.  Because of those dependencies, the sync failed, the tables look like hell with deprecated columns scattered about, PK indexes on those columns dropped, and queries performing like hot garbage.\n\nBut their code...  \nTheir comparison thought it was a different datatype because the source was VARCHAR and the target (in ***) was CHARACTER VARYING.\n\nTell me you didn\'t test your code, without saying "we didn\'t test our code"', 'author_fullname': 't2_3ymhe', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'fivetran - wth?!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eigve6', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.94, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 24, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 24, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722621928.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>They recently pushed new code to prod that seriously had me scratching my head.</p>\n\n<p>I get it, sometimes datatypes change, and fivetran will pick them up.  So they rename the existing column as deprecated, add the new one (with the new datatype), then drop the old one.  And fair enough that we had some structures that included those columns they tried to drop.  I get that&#39;s a risk and not ideal.  Because of those dependencies, the sync failed, the tables look like hell with deprecated columns scattered about, PK indexes on those columns dropped, and queries performing like hot garbage.</p>\n\n<p>But their code...<br/>\nTheir comparison thought it was a different datatype because the source was VARCHAR and the target (in ***) was CHARACTER VARYING.</p>\n\n<p>Tell me you didn&#39;t test your code, without saying &quot;we didn&#39;t test our code&quot;</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1eigve6', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='cycloscott'), 'discussion_type': None, 'num_comments': 17, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eigve6/fivetran_wth/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eigve6/fivetran_wth/', 'subreddit_subscribers': 201664, 'created_utc': 1722621928.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.325+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '….sometimes it takes me ages to read a section of a technical book and understand the theory. I then struggle to design data models and hack around for ages trying to physicalise them making numerous mistakes that I think if I was more logically minded I would have figured out in the design phase.\n\nWhat keeps me going is that I like designing systems that flow as simplistically as possible, and I want to do the same with data pipelines. It would give me a great sense of achievement.\n\nShould I keep going with data engineering or just get real; is my lack of ability to think logically going to frustrate me and hold me back forever?\n\nThanks.\n\n', 'author_fullname': 't2_8ocd2kep', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Thinking logically doesn’t come very easy to me…', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1ej118b', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 10, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 10, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722684260.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>….sometimes it takes me ages to read a section of a technical book and understand the theory. I then struggle to design data models and hack around for ages trying to physicalise them making numerous mistakes that I think if I was more logically minded I would have figured out in the design phase.</p>\n\n<p>What keeps me going is that I like designing systems that flow as simplistically as possible, and I want to do the same with data pipelines. It would give me a great sense of achievement.</p>\n\n<p>Should I keep going with data engineering or just get real; is my lack of ability to think logically going to frustrate me and hold me back forever?</p>\n\n<p>Thanks.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1ej118b', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='GlueSniffingEnabler'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1ej118b/thinking_logically_doesnt_come_very_easy_to_me/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ej118b/thinking_logically_doesnt_come_very_easy_to_me/', 'subreddit_subscribers': 201664, 'created_utc': 1722684260.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.327+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I am on a small data team. Increasingly, we need to harmonize and combine data from numerous data sources (APIs, Sharepoint, various CSVs, etc.). While we have solid R scripts able to do the extraction, cleaning, and merging, the sequencing of when certain scripts need to be executed is becoming increasingly cumbersome and complex. The amount of intermediate tables/building blocks that are useful in other contexts is also growing. And furthermore, we don't have a central location to put the data. Right now I'm funneling the cleaned data from each system into separate local databases (SQLite/duckdb), and then querying those databases to combine the data. Is the solution just 'dbt + Snowflake'? The data is actually quite small (\\~100000 rows), so I don't think we need something massive. What are some good orchestration tools for managing multiple pipelines, funneling into a single source, and then making that single source queryable by applications like PowerBI?", 'author_fullname': 't2_l9g05', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Orchestrating numerous data pipelines with small data', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eioqrz', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722641887.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am on a small data team. Increasingly, we need to harmonize and combine data from numerous data sources (APIs, Sharepoint, various CSVs, etc.). While we have solid R scripts able to do the extraction, cleaning, and merging, the sequencing of when certain scripts need to be executed is becoming increasingly cumbersome and complex. The amount of intermediate tables/building blocks that are useful in other contexts is also growing. And furthermore, we don&#39;t have a central location to put the data. Right now I&#39;m funneling the cleaned data from each system into separate local databases (SQLite/duckdb), and then querying those databases to combine the data. Is the solution just &#39;dbt + Snowflake&#39;? The data is actually quite small (~100000 rows), so I don&#39;t think we need something massive. What are some good orchestration tools for managing multiple pipelines, funneling into a single source, and then making that single source queryable by applications like PowerBI?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1eioqrz', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='bearflagswag'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eioqrz/orchestrating_numerous_data_pipelines_with_small/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eioqrz/orchestrating_numerous_data_pipelines_with_small/', 'subreddit_subscribers': 201664, 'created_utc': 1722641887.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.330+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I have a table that holds **workflow** information and the **tables** they depend on. A workflow could depend on any layer table, similarly, a table could serve as a dependency of multiple workflows. Apart from this I have fourth column which tells which workflow would create the table in second column. Basically a dependency graph between workflows. This way we know which workflow to run first followed by which. \n\nI want to visualize this information to see which workflows depend on which one like a visual flow/network diagram. I want to achieve this within the databricks (preferably without any third-party lib)\n\nWhat are my options here?\n\nhttps://preview.redd.it/fiz7jpi67bgd1.png?width=493&format=png&auto=webp&s=c095e0042f5eaa3bbd5d96b2a37bc7d3c38d1476\n\nFor above data output would be like:\n\n[DAG](https://preview.redd.it/4qpuihodabgd1.png?width=436&format=png&auto=webp&s=145f970415803f64bfda977d073d88a8374bf708)\n\n', 'author_fullname': 't2_3avqegqe', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Visualize dependencies, what are my options', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 35, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'fiz7jpi67bgd1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 27, 'x': 108, 'u': 'https://preview.redd.it/fiz7jpi67bgd1.png?width=108&crop=smart&auto=webp&s=71c541b78a7bb211473109b406e1ee9c0a9482b3'}, {'y': 54, 'x': 216, 'u': 'https://preview.redd.it/fiz7jpi67bgd1.png?width=216&crop=smart&auto=webp&s=af67768315f6008cec6194d85905c0e751ef9fd8'}, {'y': 81, 'x': 320, 'u': 'https://preview.redd.it/fiz7jpi67bgd1.png?width=320&crop=smart&auto=webp&s=a93cb46e0b47b400bcdbc26e8b49493ec9e8dab9'}], 's': {'y': 125, 'x': 493, 'u': 'https://preview.redd.it/fiz7jpi67bgd1.png?width=493&format=png&auto=webp&s=c095e0042f5eaa3bbd5d96b2a37bc7d3c38d1476'}, 'id': 'fiz7jpi67bgd1'}, '4qpuihodabgd1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 56, 'x': 108, 'u': 'https://preview.redd.it/4qpuihodabgd1.png?width=108&crop=smart&auto=webp&s=b2500f3a087e444d9babbf7c037e19a1bfef8799'}, {'y': 112, 'x': 216, 'u': 'https://preview.redd.it/4qpuihodabgd1.png?width=216&crop=smart&auto=webp&s=8443898d925500354c3144afc1f6c0e45cf4489a'}, {'y': 166, 'x': 320, 'u': 'https://preview.redd.it/4qpuihodabgd1.png?width=320&crop=smart&auto=webp&s=7e0d218df51c8125f706cedd2638c096088a3abe'}], 's': {'y': 227, 'x': 436, 'u': 'https://preview.redd.it/4qpuihodabgd1.png?width=436&format=png&auto=webp&s=145f970415803f64bfda977d073d88a8374bf708'}, 'id': '4qpuihodabgd1'}}, 'name': 't3_1eikli1', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.79, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/oyqT7g9SPPWrxFnhwHfYB5D9pCrBMaBWNMwp3pBVC10.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722631104.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I have a table that holds <strong>workflow</strong> information and the <strong>tables</strong> they depend on. A workflow could depend on any layer table, similarly, a table could serve as a dependency of multiple workflows. Apart from this I have fourth column which tells which workflow would create the table in second column. Basically a dependency graph between workflows. This way we know which workflow to run first followed by which. </p>\n\n<p>I want to visualize this information to see which workflows depend on which one like a visual flow/network diagram. I want to achieve this within the databricks (preferably without any third-party lib)</p>\n\n<p>What are my options here?</p>\n\n<p><a href="https://preview.redd.it/fiz7jpi67bgd1.png?width=493&amp;format=png&amp;auto=webp&amp;s=c095e0042f5eaa3bbd5d96b2a37bc7d3c38d1476">https://preview.redd.it/fiz7jpi67bgd1.png?width=493&amp;format=png&amp;auto=webp&amp;s=c095e0042f5eaa3bbd5d96b2a37bc7d3c38d1476</a></p>\n\n<p>For above data output would be like:</p>\n\n<p><a href="https://preview.redd.it/4qpuihodabgd1.png?width=436&amp;format=png&amp;auto=webp&amp;s=145f970415803f64bfda977d073d88a8374bf708">DAG</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1eikli1', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='saadcarnot'), 'discussion_type': None, 'num_comments': 9, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eikli1/visualize_dependencies_what_are_my_options/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eikli1/visualize_dependencies_what_are_my_options/', 'subreddit_subscribers': 201664, 'created_utc': 1722631104.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.331+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi everyone,\n\nI’m a software developer with 4 years of experience working in the insurance industry. \n\nI’m on the verge of applying for Data engineering jobs. I have taken a few months to understand data engineering, practiced a few projects and even got my Azure certification as a Data engineer.\n\nThat being said, I would like to know what are the projects you would recommend for someone to put on their portfolio . I followed a few projects on YouTube but they are not “heavy” enough for a portfolioe as a transitioning SWE. For reference, I’m looking for positions in the insurance, bank  and med tech ( did my honors in Bioinformatics). \n\nAny lead, datasets ideas or even GitHub link are much appreciated. ', 'author_fullname': 't2_kel54afu', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Project ideas for software engineer switching to DE', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1ej0bzj', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 8, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Personal Project Showcase', 'can_mod_post': False, 'score': 8, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722681754.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi everyone,</p>\n\n<p>I’m a software developer with 4 years of experience working in the insurance industry. </p>\n\n<p>I’m on the verge of applying for Data engineering jobs. I have taken a few months to understand data engineering, practiced a few projects and even got my Azure certification as a Data engineer.</p>\n\n<p>That being said, I would like to know what are the projects you would recommend for someone to put on their portfolio . I followed a few projects on YouTube but they are not “heavy” enough for a portfolioe as a transitioning SWE. For reference, I’m looking for positions in the insurance, bank  and med tech ( did my honors in Bioinformatics). </p>\n\n<p>Any lead, datasets ideas or even GitHub link are much appreciated. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '4134b452-dc3b-11ec-a21a-0262096eec38', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ddbd37', 'id': '1ej0bzj', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Equivalent_Tough_651'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1ej0bzj/project_ideas_for_software_engineer_switching_to/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ej0bzj/project_ideas_for_software_engineer_switching_to/', 'subreddit_subscribers': 201664, 'created_utc': 1722681754.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.333+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'd like to get a sense of what organizational structures look like for this community (cross posting in an analytics group as well) some questions:\n\nDo you work in a unified data group (DE, analytics, DS, Governance...), if so what does that structure look like? \n\nAre you in IT? Data within IT? Product? Data as a business unit?\n\nWhat does the position distribution look like (Analyst, DE, AE, DS, MLE?)\n\nI've been struggling as a leader for the last six months to understand what my structure should look like, battling with conflicting stakeholders/reporting chain, and generally misery of heavy IT admin overhead.\n\nTell me what yours looks like and why it works.\n\nAppreciate you helping ", 'author_fullname': 't2_4z4f1ncw', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Unified data organization ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eiqlf3', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.71, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722647165.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;d like to get a sense of what organizational structures look like for this community (cross posting in an analytics group as well) some questions:</p>\n\n<p>Do you work in a unified data group (DE, analytics, DS, Governance...), if so what does that structure look like? </p>\n\n<p>Are you in IT? Data within IT? Product? Data as a business unit?</p>\n\n<p>What does the position distribution look like (Analyst, DE, AE, DS, MLE?)</p>\n\n<p>I&#39;ve been struggling as a leader for the last six months to understand what my structure should look like, battling with conflicting stakeholders/reporting chain, and generally misery of heavy IT admin overhead.</p>\n\n<p>Tell me what yours looks like and why it works.</p>\n\n<p>Appreciate you helping </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1eiqlf3', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='ryhackett'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eiqlf3/unified_data_organization/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eiqlf3/unified_data_organization/', 'subreddit_subscribers': 201664, 'created_utc': 1722647165.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.334+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I am building a webscraping tool that fetch data from a used car listing everyday. My plan was to send the data to an S3 bucket.\nThe question is:\nsince I’m going to have a lot of duplicate car listings, what is the best way to avoid duplicate data?', 'author_fullname': 't2_mijiyrbd8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How do you deal with duplicate value in data pipeline?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1ej0pi4', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722683120.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am building a webscraping tool that fetch data from a used car listing everyday. My plan was to send the data to an S3 bucket.\nThe question is:\nsince I’m going to have a lot of duplicate car listings, what is the best way to avoid duplicate data?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1ej0pi4', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Satoru_Phat'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1ej0pi4/how_do_you_deal_with_duplicate_value_in_data/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ej0pi4/how_do_you_deal_with_duplicate_value_in_data/', 'subreddit_subscribers': 201664, 'created_utc': 1722683120.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.336+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Currently looking at the databricks academy subscription for $1500 and maybe a ML related course they offer for another $1500. My company has a lot of projects work with Databricks, so it seems like a safe bet.\n\nAnybody have any data engineering training on their wishlist or having already completed something good? Would love to get some opinions on what to spend it on.', 'author_fullname': 't2_101sbx', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'I have $2800 of tuition assistance from my company. Help me decide what to use it on before the end of the year.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eiyh28', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722674346.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Currently looking at the databricks academy subscription for $1500 and maybe a ML related course they offer for another $1500. My company has a lot of projects work with Databricks, so it seems like a safe bet.</p>\n\n<p>Anybody have any data engineering training on their wishlist or having already completed something good? Would love to get some opinions on what to spend it on.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1eiyh28', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='adam_mc'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eiyh28/i_have_2800_of_tuition_assistance_from_my_company/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eiyh28/i_have_2800_of_tuition_assistance_from_my_company/', 'subreddit_subscribers': 201664, 'created_utc': 1722674346.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.338+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'm transferring all of the CRM, financial and scheduling data to an Azure SQL server for a mid-sized org of a few hundred people. Is there any benefit to using pyspark/databricks here or will cost saving be negligible compared to an Azure Data Factory pipeline?", 'user_reports': [], 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'At what point does pyspark/databricks a significant cost improvement to ADF?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eiehfn', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': '', 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722616154.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m transferring all of the CRM, financial and scheduling data to an Azure SQL server for a mid-sized org of a few hundred people. Is there any benefit to using pyspark/databricks here or will cost saving be negligible compared to an Azure Data Factory pipeline?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1eiehfn', 'is_robot_indexable': True, 'report_reasons': None, 'author': None, 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1eiehfn/at_what_point_does_pysparkdatabricks_a/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eiehfn/at_what_point_does_pysparkdatabricks_a/', 'subreddit_subscribers': 201664, 'created_utc': 1722616154.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.339+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'm currently working as data analyst currently using Google sheets for cleaning incoming data and looker studio for viz, as volume of data is growing i need some engineering solution.\n\nWe have to clean data manually which can be done on sheet i need solution to Store existing data in some data warehousing platform. And will append daily cleaned data.", 'author_fullname': 't2_a34g6pm6', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Need a data engineering solution', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eids9l', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.84, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722614487.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m currently working as data analyst currently using Google sheets for cleaning incoming data and looker studio for viz, as volume of data is growing i need some engineering solution.</p>\n\n<p>We have to clean data manually which can be done on sheet i need solution to Store existing data in some data warehousing platform. And will append daily cleaned data.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1eids9l', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='adhi_kailash'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eids9l/need_a_data_engineering_solution/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eids9l/need_a_data_engineering_solution/', 'subreddit_subscribers': 201664, 'created_utc': 1722614487.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.340+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "For any who is the sole owner of the SSOT tables imat their company just wondering how this data is governed.\n\nFor example let's say we have a list of companies in a particular column and one company changes its name, so the table must be updated now to reflect this.\n\nWhat steps do you take to changing it in a data governance compliant way and more importantly where/how do you log the decision or comments behind the change for future audit purposes?", 'author_fullname': 't2_14ggxn', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data governance in azure databricks?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eiyymw', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722676297.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>For any who is the sole owner of the SSOT tables imat their company just wondering how this data is governed.</p>\n\n<p>For example let&#39;s say we have a list of companies in a particular column and one company changes its name, so the table must be updated now to reflect this.</p>\n\n<p>What steps do you take to changing it in a data governance compliant way and more importantly where/how do you log the decision or comments behind the change for future audit purposes?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1eiyymw', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Burnstryk'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eiyymw/data_governance_in_azure_databricks/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eiyymw/data_governance_in_azure_databricks/', 'subreddit_subscribers': 201664, 'created_utc': 1722676297.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.341+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'We wrote a blog article that compares the performance of Apache Hive 4.0 (released a few months ago) and the latest release of Trino. For running Hive, we use MR3 as the execution engine. The results may be useful to data warehouse users.\n\n\n\n[https://www.datamonad.com/post/2024-08-01-hive-4.0-performance-1.11/](https://www.datamonad.com/post/2024-08-01-hive-4.0-performance-1.11/)\n\n\n\nApache Hive is often criticized for its slow speed as a query engine. This is actually not the case, as shown in the experimental results. Still it is hard to operate, mainly because it requires the Hadoop platform.\n\n\n\nMR3 (a new execution engine) tries to eliminate this problem by making it easy to operate Hive. For example, with MR3, you can run Hive not only on Hadoop, but also directly on Kubernetes and even in standalone mode (similarly to Spark standalone mode and Trino/Presto).', 'author_fullname': 't2_ewd4yemob', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Apache Hive 4.0 and Trino 453 on the TPC-DS benchmark', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eiv3rw', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722661282.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>We wrote a blog article that compares the performance of Apache Hive 4.0 (released a few months ago) and the latest release of Trino. For running Hive, we use MR3 as the execution engine. The results may be useful to data warehouse users.</p>\n\n<p><a href="https://www.datamonad.com/post/2024-08-01-hive-4.0-performance-1.11/">https://www.datamonad.com/post/2024-08-01-hive-4.0-performance-1.11/</a></p>\n\n<p>Apache Hive is often criticized for its slow speed as a query engine. This is actually not the case, as shown in the experimental results. Still it is hard to operate, mainly because it requires the Hadoop platform.</p>\n\n<p>MR3 (a new execution engine) tries to eliminate this problem by making it easy to operate Hive. For example, with MR3, you can run Hive not only on Hadoop, but also directly on Kubernetes and even in standalone mode (similarly to Spark standalone mode and Trino/Presto).</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1eiv3rw', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='ForeignCapital8624'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eiv3rw/apache_hive_40_and_trino_453_on_the_tpcds/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eiv3rw/apache_hive_40_and_trino_453_on_the_tpcds/', 'subreddit_subscribers': 201664, 'created_utc': 1722661282.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.343+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi all. I'm an EHR technician who is I'm the process of moving into an interface analyst role. \n\nFirst, do interfaces fall under the scope of data engineers? \n\nWe will also have an integration engine, does integration fall under the scope as well?\n\nAnd how would you explain the differences between interfaces, interoperability, and integration? \n\nJust trying to find out if I'm in the right place or where I should go.\n\nAny additional information would be appreciated. This is a whole new world for me. \n\nThank you.\n\n", 'author_fullname': 't2_itk9t2szx', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Difference between different jobs that deal with data in motion.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eih3ly', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722622504.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi all. I&#39;m an EHR technician who is I&#39;m the process of moving into an interface analyst role. </p>\n\n<p>First, do interfaces fall under the scope of data engineers? </p>\n\n<p>We will also have an integration engine, does integration fall under the scope as well?</p>\n\n<p>And how would you explain the differences between interfaces, interoperability, and integration? </p>\n\n<p>Just trying to find out if I&#39;m in the right place or where I should go.</p>\n\n<p>Any additional information would be appreciated. This is a whole new world for me. </p>\n\n<p>Thank you.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1eih3ly', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Specific-Good-1827'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eih3ly/difference_between_different_jobs_that_deal_with/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eih3ly/difference_between_different_jobs_that_deal_with/', 'subreddit_subscribers': 201664, 'created_utc': 1722622504.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.355+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi all. I’m having quite a hard time coming with a solution for a pipeline with quite a bit of data volume. In a normal week, the volume is at 150k requests, which is quite a lot for Airflow. In terms of technology, im kinda bound to GCP as thats the main provider and Airflow.\nIn simple words, i need to get some data from an Oracle DataBase and make some requests to an internal API. \nI was thinking of doing an ELT pipeline:\nGet data from on-prem db -> load to object storage -> transform into the needed body format -> post the responses\nWhat are your thoughts on optimization so that i can do these requests as fast as possible - keeping in mind that sometimes there are 429 responses and i will need to re-try after a cooldown period.\n\nThanks a lot!', 'author_fullname': 't2_81yswwb6', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Solution for optimized flow of post requests to an API', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1ej1s66', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722686779.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi all. I’m having quite a hard time coming with a solution for a pipeline with quite a bit of data volume. In a normal week, the volume is at 150k requests, which is quite a lot for Airflow. In terms of technology, im kinda bound to GCP as thats the main provider and Airflow.\nIn simple words, i need to get some data from an Oracle DataBase and make some requests to an internal API. \nI was thinking of doing an ELT pipeline:\nGet data from on-prem db -&gt; load to object storage -&gt; transform into the needed body format -&gt; post the responses\nWhat are your thoughts on optimization so that i can do these requests as fast as possible - keeping in mind that sometimes there are 429 responses and i will need to re-try after a cooldown period.</p>\n\n<p>Thanks a lot!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1ej1s66', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Imalrightiswear'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1ej1s66/solution_for_optimized_flow_of_post_requests_to/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ej1s66/solution_for_optimized_flow_of_post_requests_to/', 'subreddit_subscribers': 201664, 'created_utc': 1722686779.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.356+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I will probably buy my first car soon so I am building a web scraper to collect data from autoscout24 (used cars website). Can you help me build the data stack?  \nConsider this when making it:  \n1. Make it overkill on purpouse. I am making this mainly to learn something  \n2. Use dagster as orchestrator   \n3. Python  \n4. Cover the visualization part', 'author_fullname': 't2_mijiyrbd8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Help this noob build his data stack', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eih0bk', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.58, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722622273.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I will probably buy my first car soon so I am building a web scraper to collect data from autoscout24 (used cars website). Can you help me build the data stack?<br/>\nConsider this when making it:<br/>\n1. Make it overkill on purpouse. I am making this mainly to learn something<br/>\n2. Use dagster as orchestrator<br/>\n3. Python<br/>\n4. Cover the visualization part</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1eih0bk', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Satoru_Phat'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eih0bk/help_this_noob_build_his_data_stack/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eih0bk/help_this_noob_build_his_data_stack/', 'subreddit_subscribers': 201664, 'created_utc': 1722622273.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.357+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'can anyone review  manish kumar spark playlist on youtoube? good for a beginner? any other resource suggestions. ', 'author_fullname': 't2_z8avl3yve', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Manish Kumar Spark playlist', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eiynsa', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.57, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722675111.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>can anyone review  manish kumar spark playlist on youtoube? good for a beginner? any other resource suggestions. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1eiynsa', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Living_Challenge_637'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eiynsa/manish_kumar_spark_playlist/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eiynsa/manish_kumar_spark_playlist/', 'subreddit_subscribers': 201664, 'created_utc': 1722675111.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.359+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Which simple tool is used is most of in Data engineers. \n       There is any specific needs as a data engineers need. \n        \n     \nLike, \n       Xls to CSV', 'author_fullname': 't2_v1x4dcgm9', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Tools ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eiswrd', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.25, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722654184.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Which simple tool is used is most of in Data engineers. \n       There is any specific needs as a data engineers need. </p>\n\n<p>Like, \n       Xls to CSV</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1eiswrd', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Asleep_Tank6703'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eiswrd/tools/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eiswrd/tools/', 'subreddit_subscribers': 201664, 'created_utc': 1722654184.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.360+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f6846a703d0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi everyone,\n\nI've been working as a Data Engineer in Europe for the past few years, and I've recently noticed a decline in the number of job vacancies in my field. This has made me wonder about the current demand and future prospects for data engineers.\n\nI'm curious to hear your thoughts and experiences. Are you noticing a similar trend in your region? Do you think the role of data engineer is still valuable in today's job market? What skills or specializations do you think are becoming more important for data engineers to stay relevant?\n\nThanks in advance for your insights!", 'author_fullname': 't2_6zhipiyk', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Is the Role of Data Engineer Still Valuable? Seeking Opinions', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1eiwl0g', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.41, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1722666781.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi everyone,</p>\n\n<p>I&#39;ve been working as a Data Engineer in Europe for the past few years, and I&#39;ve recently noticed a decline in the number of job vacancies in my field. This has made me wonder about the current demand and future prospects for data engineers.</p>\n\n<p>I&#39;m curious to hear your thoughts and experiences. Are you noticing a similar trend in your region? Do you think the role of data engineer is still valuable in today&#39;s job market? What skills or specializations do you think are becoming more important for data engineers to stay relevant?</p>\n\n<p>Thanks in advance for your insights!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1eiwl0g', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Euphoric-Worker-8516'), 'discussion_type': None, 'num_comments': 10, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1eiwl0g/is_the_role_of_data_engineer_still_valuable/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eiwl0g/is_the_role_of_data_engineer_still_valuable/', 'subreddit_subscribers': 201664, 'created_utc': 1722666781.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-08-03T13:44:54.361+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-08-03T13:44:54.410+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, execution_date=20240803T134450, start_date=20240803T134452, end_date=20240803T134454
[2024-08-03T13:44:54.550+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-08-03T13:44:54.606+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
